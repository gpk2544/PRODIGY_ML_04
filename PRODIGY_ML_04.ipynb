{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNkACV42RpqGjdUCZmUo+ik"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zbEh_llUzeqD","executionInfo":{"status":"ok","timestamp":1721389948052,"user_tz":-330,"elapsed":491542,"user":{"displayName":"Krishnesh G P","userId":"02673702448712265825"}},"outputId":"107ed346-8943-413e-e381-eafc2f6371f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","Epoch 1/10\n","469/469 [==============================] - 66s 137ms/step - loss: 0.2252 - accuracy: 0.9354 - val_loss: 0.0556 - val_accuracy: 0.9820\n","Epoch 2/10\n","469/469 [==============================] - 45s 97ms/step - loss: 0.0584 - accuracy: 0.9819 - val_loss: 0.0557 - val_accuracy: 0.9819\n","Epoch 3/10\n","469/469 [==============================] - 45s 95ms/step - loss: 0.0415 - accuracy: 0.9869 - val_loss: 0.0369 - val_accuracy: 0.9864\n","Epoch 4/10\n","469/469 [==============================] - 49s 104ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.0315 - val_accuracy: 0.9895\n","Epoch 5/10\n","469/469 [==============================] - 44s 94ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.0276 - val_accuracy: 0.9907\n","Epoch 6/10\n","469/469 [==============================] - 46s 97ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.0300 - val_accuracy: 0.9902\n","Epoch 7/10\n","469/469 [==============================] - 43s 92ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0457 - val_accuracy: 0.9859\n","Epoch 8/10\n","469/469 [==============================] - 44s 95ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0299 - val_accuracy: 0.9908\n","Epoch 9/10\n","469/469 [==============================] - 46s 99ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0340 - val_accuracy: 0.9884\n","Epoch 10/10\n","469/469 [==============================] - 45s 96ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0315 - val_accuracy: 0.9907\n","Test loss: 0.03147818148136139\n","Test accuracy: 0.9907000064849854\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","import cv2\n","import numpy as np\n","\n","# Load the dataset\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","# Preprocess the data\n","x_train = x_train.reshape(-1, 28, 28, 1)\n","x_test = x_test.reshape(-1, 28, 28, 1)\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","\n","# Define the model architecture\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(10, activation='softmax'))\n","\n","# Compile the model\n","model.compile(loss=tf.keras.losses.categorical_crossentropy,\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=10,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","\n","# Test the model\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n","\n","# Real-time testing using a webcam\n","def real_time_test():\n","    cap = cv2.VideoCapture(0)\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, (28, 28))\n","        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        frame = np.expand_dims(frame, axis=-1)\n","        frame = frame.astype('float32') / 255\n","        frame = np.expand_dims(frame, axis=0)\n","        prediction = model.predict(frame)\n","        predicted_class = np.argmax(prediction)\n","        cv2.putText(frame, str(predicted_class), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n","        cv2.imshow('Hand Gesture Recognition', frame)\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","real_time_test()"]}]}